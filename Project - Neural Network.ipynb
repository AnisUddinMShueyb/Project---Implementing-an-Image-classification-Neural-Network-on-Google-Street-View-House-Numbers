{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJECT _ NEURAL NETWORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pylab as plt\n",
    "import tensorflow as tf\n",
    "import random\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the SVHN Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5f = h5py.File('SVHN_single_grey1.h5','r')\n",
    "\n",
    "h5f.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the train/test/val splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = h5f['X_train'][:]\n",
    "y_train = h5f['y_train'][:]\n",
    "X_test = h5f['X_test'][:]\n",
    "y_test = h5f['y_test'][:]\n",
    "X_val = h5f['X_val'][:]\n",
    "y_val = h5f['y_val'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sets contain RGB codes (from 0 to 255) while y_train and y_test contains labels from 0 to 9 which represents which number they actually are.\n",
    "\n",
    "Let's visualize some numbers using below function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19e00007e88>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(\"Label: {}\".format(y_train[5000]))\n",
    "plt.imshow(X_train[5000], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (42000, 32, 32) (42000,)\n",
      "Test set: (18000, 32, 32) (18000,)\n",
      "Validation set: (60000, 32, 32) (60000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set:\", X_test.shape, y_test.shape)\n",
    "print(\"Validation set:\", X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 32, 32, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 32, 32, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], 32, 32, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_val /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape of data and number of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (42000, 32, 32, 1)\n",
      "Images in X_train: 42000\n",
      "Images in X_test: 18000\n",
      "Max value in X_train: 0.9999\n",
      "Min value in X_train: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"Images in X_train:\", X_train.shape[0])\n",
    "print(\"Images in X_test:\", X_test.shape[0])\n",
    "print(\"Max value in X_train:\", X_train.max())\n",
    "print(\"Min value in X_train:\", X_train.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train: (42000, 10)\n",
      "One value of y_train: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "y_val = to_categorical(y_val, num_classes=10)\n",
    "\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"One value of y_train:\", y_train[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing sequential network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling and fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 6s 145us/sample - loss: 2.2826 - acc: 0.1252 - val_loss: 2.2100 - val_acc: 0.1748\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 8s 192us/sample - loss: 2.1109 - acc: 0.2089 - val_loss: 2.0362 - val_acc: 0.2379\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 9s 220us/sample - loss: 2.0222 - acc: 0.2378 - val_loss: 1.9974 - val_acc: 0.2472\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 7s 167us/sample - loss: 1.9964 - acc: 0.2459 - val_loss: 1.9818 - val_acc: 0.2538\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 7s 177us/sample - loss: 1.9800 - acc: 0.2493 - val_loss: 1.9618 - val_acc: 0.2590\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 9s 216us/sample - loss: 1.9717 - acc: 0.2498 - val_loss: 1.9806 - val_acc: 0.2428\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 7s 159us/sample - loss: 1.9616 - acc: 0.2638 - val_loss: 1.9540 - val_acc: 0.2664\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 4s 100us/sample - loss: 1.9534 - acc: 0.2680 - val_loss: 1.9376 - val_acc: 0.2711\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 5s 125us/sample - loss: 1.9505 - acc: 0.2657 - val_loss: 1.9537 - val_acc: 0.2607\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 6s 149us/sample - loss: 1.9428 - acc: 0.2684 - val_loss: 1.9287 - val_acc: 0.2779\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 7s 167us/sample - loss: 1.9381 - acc: 0.2677 - val_loss: 1.9532 - val_acc: 0.2560\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 9s 215us/sample - loss: 1.9328 - acc: 0.2671 - val_loss: 1.9322 - val_acc: 0.2688\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 9s 219us/sample - loss: 1.9286 - acc: 0.2655 - val_loss: 1.9139 - val_acc: 0.2709\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 7s 162us/sample - loss: 1.9256 - acc: 0.2676 - val_loss: 1.9256 - val_acc: 0.2725\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 8s 182us/sample - loss: 1.9238 - acc: 0.2657 - val_loss: 1.9126 - val_acc: 0.2646\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 6s 151us/sample - loss: 1.9179 - acc: 0.2683 - val_loss: 1.9011 - val_acc: 0.2697\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 5s 128us/sample - loss: 1.9149 - acc: 0.2654 - val_loss: 1.9270 - val_acc: 0.2622\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 8s 185us/sample - loss: 1.9116 - acc: 0.2657 - val_loss: 1.9002 - val_acc: 0.2726\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 8s 179us/sample - loss: 1.9131 - acc: 0.2639 - val_loss: 1.8958 - val_acc: 0.2754\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 5s 114us/sample - loss: 1.9081 - acc: 0.2646 - val_loss: 1.8974 - val_acc: 0.2715\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 8s 184us/sample - loss: 1.9099 - acc: 0.2632 - val_loss: 1.9367 - val_acc: 0.2525\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 7s 168us/sample - loss: 1.9056 - acc: 0.2644 - val_loss: 1.9044 - val_acc: 0.2663\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 8s 195us/sample - loss: 1.9020 - acc: 0.2646 - val_loss: 1.9032 - val_acc: 0.2623\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 4s 91us/sample - loss: 1.9015 - acc: 0.2641 - val_loss: 1.9057 - val_acc: 0.2599\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 5s 126us/sample - loss: 1.9011 - acc: 0.2602 - val_loss: 1.8886 - val_acc: 0.2738\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 7s 156us/sample - loss: 1.8999 - acc: 0.2618 - val_loss: 1.8883 - val_acc: 0.2676\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 6s 154us/sample - loss: 1.8970 - acc: 0.2645 - val_loss: 1.8866 - val_acc: 0.2668\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 8s 183us/sample - loss: 1.8956 - acc: 0.2677 - val_loss: 1.8877 - val_acc: 0.2613\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 7s 164us/sample - loss: 1.8963 - acc: 0.2685 - val_loss: 1.8852 - val_acc: 0.2719\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 8s 194us/sample - loss: 1.8947 - acc: 0.2707 - val_loss: 1.8967 - val_acc: 0.2666\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 6s 153us/sample - loss: 1.8947 - acc: 0.2707 - val_loss: 1.9277 - val_acc: 0.2578\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 4s 103us/sample - loss: 1.8926 - acc: 0.2682 - val_loss: 1.8823 - val_acc: 0.2680\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 3s 75us/sample - loss: 1.8890 - acc: 0.2694 - val_loss: 1.8793 - val_acc: 0.2749\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 5s 123us/sample - loss: 1.8922 - acc: 0.2682 - val_loss: 1.8818 - val_acc: 0.2742\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 8s 193us/sample - loss: 1.8916 - acc: 0.2682 - val_loss: 1.9046 - val_acc: 0.2615\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 7s 166us/sample - loss: 1.8905 - acc: 0.2686 - val_loss: 1.9220 - val_acc: 0.2530\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 6s 152us/sample - loss: 1.8893 - acc: 0.2698 - val_loss: 1.8889 - val_acc: 0.2628\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 8s 183us/sample - loss: 1.8896 - acc: 0.2665 - val_loss: 1.8847 - val_acc: 0.2677\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 7s 161us/sample - loss: 1.8858 - acc: 0.2693 - val_loss: 1.8777 - val_acc: 0.2739\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 9s 210us/sample - loss: 1.8857 - acc: 0.2677 - val_loss: 1.9053 - val_acc: 0.2565\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 9s 204us/sample - loss: 1.8864 - acc: 0.2652 - val_loss: 1.8885 - val_acc: 0.2704\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 7s 167us/sample - loss: 1.8867 - acc: 0.2684 - val_loss: 1.8796 - val_acc: 0.2700\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 6s 142us/sample - loss: 1.8839 - acc: 0.2694 - val_loss: 1.9034 - val_acc: 0.2544\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 6s 140us/sample - loss: 1.8848 - acc: 0.2667 - val_loss: 1.8854 - val_acc: 0.2679\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 8s 180us/sample - loss: 1.8831 - acc: 0.2701 - val_loss: 1.8838 - val_acc: 0.2623\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 9s 224us/sample - loss: 1.8828 - acc: 0.2695 - val_loss: 1.8932 - val_acc: 0.2595\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 8s 180us/sample - loss: 1.8801 - acc: 0.2697 - val_loss: 1.8729 - val_acc: 0.2707\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 5s 127us/sample - loss: 1.8814 - acc: 0.2685 - val_loss: 1.8826 - val_acc: 0.2665\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 7s 156us/sample - loss: 1.8808 - acc: 0.2697 - val_loss: 1.8685 - val_acc: 0.2706\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 6s 140us/sample - loss: 1.8811 - acc: 0.2680 - val_loss: 1.8852 - val_acc: 0.2690\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 8s 195us/sample - loss: 1.8831 - acc: 0.2686 - val_loss: 1.8938 - val_acc: 0.2642\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 5s 108us/sample - loss: 1.8819 - acc: 0.2673 - val_loss: 1.8727 - val_acc: 0.2735\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 4s 87us/sample - loss: 1.8816 - acc: 0.2680 - val_loss: 1.8734 - val_acc: 0.2694\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 4s 102us/sample - loss: 1.8793 - acc: 0.2711 - val_loss: 1.8870 - val_acc: 0.2620\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 8s 201us/sample - loss: 1.8767 - acc: 0.2731 - val_loss: 1.8705 - val_acc: 0.2725\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 8s 190us/sample - loss: 1.8773 - acc: 0.2696 - val_loss: 1.8977 - val_acc: 0.2563\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 7s 162us/sample - loss: 1.8814 - acc: 0.2689 - val_loss: 1.8693 - val_acc: 0.2781\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 9s 208us/sample - loss: 1.8798 - acc: 0.2708 - val_loss: 1.8806 - val_acc: 0.2651\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 8s 190us/sample - loss: 1.8769 - acc: 0.2707 - val_loss: 1.8675 - val_acc: 0.2699\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 6s 146us/sample - loss: 1.8766 - acc: 0.2710 - val_loss: 1.8868 - val_acc: 0.2663\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 7s 168us/sample - loss: 1.8753 - acc: 0.2733 - val_loss: 1.8870 - val_acc: 0.2602\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 8s 183us/sample - loss: 1.8775 - acc: 0.2715 - val_loss: 1.9027 - val_acc: 0.2627\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 7s 176us/sample - loss: 1.8779 - acc: 0.2702 - val_loss: 1.8767 - val_acc: 0.2704\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 8s 200us/sample - loss: 1.8737 - acc: 0.2702 - val_loss: 1.8760 - val_acc: 0.2763\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 8s 188us/sample - loss: 1.8740 - acc: 0.2737 - val_loss: 1.8772 - val_acc: 0.2713\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 7s 172us/sample - loss: 1.8780 - acc: 0.2723 - val_loss: 1.8644 - val_acc: 0.2714\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 7s 170us/sample - loss: 1.8782 - acc: 0.2685 - val_loss: 1.8771 - val_acc: 0.2738\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 7s 164us/sample - loss: 1.8740 - acc: 0.2723 - val_loss: 1.8699 - val_acc: 0.2732\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 7s 173us/sample - loss: 1.8767 - acc: 0.2727 - val_loss: 1.8759 - val_acc: 0.2707\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 8s 181us/sample - loss: 1.8762 - acc: 0.2733 - val_loss: 1.8825 - val_acc: 0.2699\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 8s 194us/sample - loss: 1.8737 - acc: 0.2722 - val_loss: 1.8809 - val_acc: 0.2713\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 8s 202us/sample - loss: 1.8711 - acc: 0.2725 - val_loss: 1.8665 - val_acc: 0.2754\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 7s 167us/sample - loss: 1.8732 - acc: 0.2720 - val_loss: 1.8708 - val_acc: 0.2810\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 6s 144us/sample - loss: 1.8736 - acc: 0.2743 - val_loss: 1.8643 - val_acc: 0.2784\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 5s 128us/sample - loss: 1.8743 - acc: 0.2707 - val_loss: 1.8927 - val_acc: 0.2649\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 7s 159us/sample - loss: 1.8741 - acc: 0.2711 - val_loss: 1.8965 - val_acc: 0.2680\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 7s 158us/sample - loss: 1.8741 - acc: 0.2743 - val_loss: 1.8630 - val_acc: 0.2787\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 8s 185us/sample - loss: 1.8722 - acc: 0.2741 - val_loss: 1.9167 - val_acc: 0.2558\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 7s 165us/sample - loss: 1.8722 - acc: 0.2750 - val_loss: 1.8615 - val_acc: 0.2757\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 7s 167us/sample - loss: 1.8724 - acc: 0.2730 - val_loss: 1.8629 - val_acc: 0.2817\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 8s 192us/sample - loss: 1.8730 - acc: 0.2768 - val_loss: 1.8729 - val_acc: 0.2733\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 8s 192us/sample - loss: 1.8715 - acc: 0.2729 - val_loss: 1.8698 - val_acc: 0.2762\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 8s 202us/sample - loss: 1.8697 - acc: 0.2745 - val_loss: 1.8636 - val_acc: 0.2801\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 7s 164us/sample - loss: 1.8701 - acc: 0.2771 - val_loss: 1.9011 - val_acc: 0.2626\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 7s 174us/sample - loss: 1.8726 - acc: 0.2738 - val_loss: 1.8601 - val_acc: 0.2784\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 7s 165us/sample - loss: 1.8699 - acc: 0.2777 - val_loss: 1.8700 - val_acc: 0.2754\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 7s 175us/sample - loss: 1.8741 - acc: 0.2743 - val_loss: 1.8897 - val_acc: 0.2726\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 7s 169us/sample - loss: 1.8692 - acc: 0.2756 - val_loss: 1.8650 - val_acc: 0.2787\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 8s 191us/sample - loss: 1.8726 - acc: 0.2747 - val_loss: 1.8747 - val_acc: 0.2751\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 6s 142us/sample - loss: 1.8695 - acc: 0.2744 - val_loss: 1.8649 - val_acc: 0.2798\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 6s 148us/sample - loss: 1.8702 - acc: 0.2731 - val_loss: 1.8663 - val_acc: 0.2806\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 6s 135us/sample - loss: 1.8682 - acc: 0.2772 - val_loss: 1.8751 - val_acc: 0.2753\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 7s 158us/sample - loss: 1.8678 - acc: 0.2760 - val_loss: 1.8697 - val_acc: 0.2762\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 5s 120us/sample - loss: 1.8695 - acc: 0.2746 - val_loss: 1.8973 - val_acc: 0.2664\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 7s 160us/sample - loss: 1.8675 - acc: 0.2744 - val_loss: 1.8717 - val_acc: 0.2740\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 7s 160us/sample - loss: 1.8683 - acc: 0.2773 - val_loss: 1.8645 - val_acc: 0.2781\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 6s 151us/sample - loss: 1.8677 - acc: 0.2764 - val_loss: 1.9422 - val_acc: 0.2485\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 7s 169us/sample - loss: 1.8695 - acc: 0.2739 - val_loss: 1.8586 - val_acc: 0.2820\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 7s 174us/sample - loss: 1.8683 - acc: 0.2764 - val_loss: 1.8710 - val_acc: 0.2758\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 7s 168us/sample - loss: 1.8680 - acc: 0.2767 - val_loss: 1.9037 - val_acc: 0.2624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19e02f57bc8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=\"Adam\")\n",
    "\n",
    "# Fit the model\n",
    "model.fit(x=X_train, y=y_train, batch_size=32, epochs=100, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 0s 21us/sample - loss: 1.9146 - acc: 0.2610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9145975242190891, 0.261]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
